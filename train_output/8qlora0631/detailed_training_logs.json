{
  "training_args": {
    "model_name_or_path": "/home/asri/RAG-Retrieval/rag_retrieval/train/embedding/output/4500datas_summary20250601_epoch11-20_1e-4_losscheck/checkpoint-epoch-1/merge",
    "train_dataset": "/home/asri/FlagEmbedding/bge_data_gen/data/1140606/tsd_feedback_data_be200_0606.jsonl",
    "output_dir": "/home/asri/EmbedRAG/train_output/8qlora0631",
    "batch_size": 1,
    "neg_nums": 8,
    "query_max_len": 128,
    "passage_max_len": 1000,
    "lr": 0.0001,
    "epochs": 3,
    "save_on_epoch_end": 1,
    "gradient_accumulation_steps": 16,
    "warmup_proportion": 0.05,
    "temperature": 0.02,
    "seed": 42,
    "log_with": "tensorboard",
    "finetune_type": "qlora",
    "quantization_bits": 8,
    "lora_r": 8,
    "lora_alpha": 32,
    "lora_dropout": 0.1
  },
  "model_info": {
    "finetune_type": "qlora",
    "quantization_bits": 8,
    "total_parameters": 1552501248,
    "trainable_parameters": 9232384,
    "trainable_percentage": 0.5946780404778135,
    "lora_config": {
      "r": 8,
      "alpha": 32,
      "dropout": 0.1
    }
  },
  "step_logs": [
    {
      "epoch": 1,
      "step": 1,
      "global_step": 0,
      "loss": 0.0440082885324955,
      "learning_rate": 0.0001,
      "step_duration": 6.468711614608765,
      "timestamp": "2025-06-30T17:57:03.739793"
    },
    {
      "epoch": 1,
      "step": 2,
      "global_step": 1,
      "loss": 0.11640667915344238,
      "learning_rate": 0.0001,
      "step_duration": 5.684281587600708,
      "timestamp": "2025-06-30T17:57:09.425603"
    },
    {
      "epoch": 1,
      "step": 3,
      "global_step": 2,
      "loss": 0.9852257966995239,
      "learning_rate": 0.0001,
      "step_duration": 5.657235860824585,
      "timestamp": "2025-06-30T17:57:15.083693"
    },
    {
      "epoch": 1,
      "step": 4,
      "global_step": 3,
      "loss": 0.02582472749054432,
      "learning_rate": 0.0001,
      "step_duration": 5.599807262420654,
      "timestamp": "2025-06-30T17:57:20.684441"
    },
    {
      "epoch": 1,
      "step": 5,
      "global_step": 4,
      "loss": 0.5593200922012329,
      "learning_rate": 9.890738003669029e-05,
      "step_duration": 5.723439455032349,
      "timestamp": "2025-06-30T17:57:26.565972"
    },
    {
      "epoch": 2,
      "step": 1,
      "global_step": 5,
      "loss": 0.05690702795982361,
      "learning_rate": 9.890738003669029e-05,
      "step_duration": 5.78877067565918,
      "timestamp": "2025-06-30T17:57:35.872699"
    },
    {
      "epoch": 2,
      "step": 2,
      "global_step": 6,
      "loss": 0.010664967820048332,
      "learning_rate": 9.890738003669029e-05,
      "step_duration": 5.561012268066406,
      "timestamp": "2025-06-30T17:57:41.434917"
    },
    {
      "epoch": 2,
      "step": 3,
      "global_step": 7,
      "loss": 0.042541325092315674,
      "learning_rate": 9.890738003669029e-05,
      "step_duration": 5.555864095687866,
      "timestamp": "2025-06-30T17:57:46.991668"
    },
    {
      "epoch": 2,
      "step": 4,
      "global_step": 8,
      "loss": 0.17866432666778564,
      "learning_rate": 9.890738003669029e-05,
      "step_duration": 5.661865949630737,
      "timestamp": "2025-06-30T17:57:52.654474"
    },
    {
      "epoch": 2,
      "step": 5,
      "global_step": 9,
      "loss": 0.0019595485646277666,
      "learning_rate": 9.567727288213005e-05,
      "step_duration": 5.62318754196167,
      "timestamp": "2025-06-30T17:57:58.445735"
    },
    {
      "epoch": 3,
      "step": 1,
      "global_step": 10,
      "loss": 0.006403523031622171,
      "learning_rate": 9.567727288213005e-05,
      "step_duration": 5.627474069595337,
      "timestamp": "2025-06-30T17:58:05.968350"
    },
    {
      "epoch": 3,
      "step": 2,
      "global_step": 11,
      "loss": 0.00892353244125843,
      "learning_rate": 9.567727288213005e-05,
      "step_duration": 5.675684690475464,
      "timestamp": "2025-06-30T17:58:11.645361"
    },
    {
      "epoch": 3,
      "step": 3,
      "global_step": 12,
      "loss": 0.002546284580603242,
      "learning_rate": 9.567727288213005e-05,
      "step_duration": 5.58968186378479,
      "timestamp": "2025-06-30T17:58:17.235923"
    },
    {
      "epoch": 3,
      "step": 4,
      "global_step": 13,
      "loss": 0.0019443194614723325,
      "learning_rate": 9.567727288213005e-05,
      "step_duration": 5.6620190143585205,
      "timestamp": "2025-06-30T17:58:22.898879"
    },
    {
      "epoch": 3,
      "step": 5,
      "global_step": 14,
      "loss": 0.0065650735050439835,
      "learning_rate": 9.045084971874738e-05,
      "step_duration": 5.62928318977356,
      "timestamp": "2025-06-30T17:58:28.690501"
    }
  ],
  "epoch_logs": [
    {
      "epoch": 1,
      "avg_loss": 0.34615713357925415,
      "total_loss": 1.730785608291626,
      "num_steps": 5,
      "epoch_duration": 31.106337547302246,
      "learning_rate": 9.890738003669029e-05,
      "timestamp": "2025-06-30T17:57:26.567776"
    },
    {
      "epoch": 2,
      "avg_loss": 0.05814744159579277,
      "total_loss": 0.29073721170425415,
      "num_steps": 5,
      "epoch_duration": 30.14961886405945,
      "learning_rate": 9.567727288213005e-05,
      "timestamp": "2025-06-30T17:57:58.447370"
    },
    {
      "epoch": 3,
      "avg_loss": 0.005276546813547611,
      "total_loss": 0.02638273313641548,
      "num_steps": 5,
      "epoch_duration": 30.13032102584839,
      "learning_rate": 9.045084971874738e-05,
      "timestamp": "2025-06-30T17:58:28.692019"
    }
  ],
  "training_start_time": "2025-06-30T17:56:55.455281",
  "training_end_time": "2025-06-30T17:58:28.869439",
  "training_summary": {
    "total_training_time": 93.41416716575623,
    "total_epochs": 3,
    "total_steps": 15,
    "final_loss": 0.005276546813547611,
    "best_loss": 0.005276546813547611,
    "avg_step_duration": 5.700554609298706
  }
}